{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc106aa6-65c8-49e4-b634-bb929eb86dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dictionaries...\n",
      "Processing series file...\n",
      "Processing ce.data.02b.AllRealEarningsAE.txt...\n",
      "Saved processed data to ce_AllEarnAE_processed_data.csv. Number of rows: 302992\n",
      "Processing ce.data.05b.TotalPrivate.AllEmployeeHoursAndEarnings.txt...\n",
      "Saved processed data to ce_TotalPrivateAEHrsEarn_processed_data.csv. Number of rows: 5713\n",
      "Processing ce.data.50b.Information.AllEmployeeHoursAndEarnings.txt...\n",
      "Saved processed data to ce_InfoAEHrsEarn_processed_data.csv. Number of rows: 37534\n",
      "Processing ce.data.55b.FinancialActivities.AllEmployeeHoursAndEarnings.txt...\n",
      "Saved processed data to ce_FinlAEHrsEarn_processed_data.csv. Number of rows: 101318\n",
      "Processing ce.data.60b.ProfessionalBusinessServices.AllEmployeeHoursAndEarnings.txt...\n",
      "Saved processed data to ce_ProfAEHrsEarn_processed_data.csv. Number of rows: 135086\n",
      "Processing ce.data.65b.EducationAndHealthCare.AllEmployeeHoursAndEarnings.txt...\n",
      "Saved processed data to ce_EducHlthAEHrsEarn_processed_data.csv. Number of rows: 91938\n",
      "Processing ce.data.70b.LeisureAndHospitality.AllEmployeeHoursAndEarnings.txt...\n",
      "Saved processed data to ce_LeisAEHrsEarn_processed_data.csv. Number of rows: 69426\n",
      "Processing ce.data.80b.OtherServices.AllEmployeeHoursAndEarnings.txt...\n",
      "Saved processed data to ce_OtherAEHrsEarn_processed_data.csv. Number of rows: 73178\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to load and process the dictionaries\n",
    "def load_dictionaries(supersector_dict_path, industry_dict_path, datatype_dict_path, period_dict_path):\n",
    "    # Helper function to clean and load dictionary files\n",
    "    def load_clean_dict(file_path, key_col, value_col):\n",
    "        df = pd.read_csv(file_path, sep='\\t', header=None, usecols=[key_col, value_col])\n",
    "        df.columns = ['key', 'value']  # Rename for clarity\n",
    "        df['key'] = df['key'].str.strip()  # Strip whitespace from keys\n",
    "        df['value'] = df['value'].str.strip()  # Strip whitespace from values\n",
    "        return df.set_index('key')['value'].to_dict()  # Convert to dictionary\n",
    "\n",
    "    # Load all dictionaries\n",
    "    supersector_dict = load_clean_dict(supersector_dict_path, 0, 1)\n",
    "    industry_dict = load_clean_dict(industry_dict_path, 0, 3)\n",
    "    datatype_dict = load_clean_dict(datatype_dict_path, 0, 1)\n",
    "    period_dict = load_clean_dict(period_dict_path, 0, 2)  \n",
    "\n",
    "    return supersector_dict, industry_dict, datatype_dict, period_dict\n",
    "\n",
    "\n",
    "# Function to process the series file\n",
    "def process_series_file(series_file, supersector_dict, industry_dict, datatype_dict):\n",
    "    try:\n",
    "        series_data = pd.read_csv(series_file, sep='\\t', skipinitialspace=True)\n",
    "\n",
    "        # Strip any whitespace characters from the column names\n",
    "        series_data.columns = series_data.columns.str.strip()\n",
    "        \n",
    "        # Convert necessary columns to string and strip any whitespace from series values\n",
    "        series_data['series_id'] = series_data['series_id'].astype(str).str.strip()\n",
    "        series_data['supersector_code'] = series_data['supersector_code'].astype(str).str.strip().str.zfill(2) \n",
    "        series_data['industry_code'] = series_data['industry_code'].astype(str).str.strip().str.zfill(8)\n",
    "        series_data['data_type_code'] = series_data['data_type_code'].astype(str).str.strip().str.zfill(2)\n",
    "        \n",
    "        # Replace placeholder '-' with NA\n",
    "        series_data.replace('-', pd.NA, inplace=True)\n",
    "\n",
    "        # Map dictionary values to their names\n",
    "        series_data['supersector'] = series_data['supersector_code'].map(supersector_dict)\n",
    "        series_data['industry'] = series_data['industry_code'].map(industry_dict)\n",
    "        series_data['datatype'] = series_data['data_type_code'].map(datatype_dict)\n",
    "        \n",
    "        # Keep only the necessary columns\n",
    "        series_data = series_data[['series_id', \n",
    "                                   'supersector_code', 'supersector', \n",
    "                                   'industry_code', 'industry', \n",
    "                                   'data_type_code', 'datatype']]\n",
    "        \n",
    "        return series_data\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError encountered: {e}. Check column names or data.\")\n",
    "        raise  # Re-raise the error after logging the message\n",
    "\n",
    "\n",
    "# Function to process the AllEarnAE data file\n",
    "def process_AllEarnAE_file(AllEarnAE_file, series_data, period_dict, start_year):\n",
    "    try:\n",
    "        # Read the data file\n",
    "        data = pd.read_csv(AllEarnAE_file, sep='\\t', engine='python')\n",
    "\n",
    "        # Strip any whitespace characters from the column names\n",
    "        data.columns = data.columns.str.strip()\n",
    "\n",
    "        # Explicitly clean the series_id column for consistency\n",
    "        data['series_id'] = data['series_id'].astype(str).str.strip()\n",
    "\n",
    "        # Convert the year column to numeric for filtering and filter rows based on the start_year\n",
    "        data['year'] = pd.to_numeric(data['year'], errors='coerce')\n",
    "        data = data[data['year'] >= start_year]\n",
    "\n",
    "        # Map period code to name using period_dict\n",
    "        data['period'] = data['period'].map(period_dict)\n",
    "\n",
    "        # Merge with series data based on series_id\n",
    "        merged1_data = pd.merge(data, series_data, on='series_id', how='left')\n",
    "\n",
    "        # Keep only the relevant columns\n",
    "        final1_data = merged1_data[['series_id', 'year', 'value', \n",
    "                                   'supersector', 'industry', 'datatype', 'period']]\n",
    "\n",
    "        return final1_data\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError encountered: {e}. Check column names or data.\")\n",
    "        raise  # Re-raise the error after logging the message\n",
    "\n",
    "# Function to process the ...HrsEarn data files\n",
    "def process_HrsEarn_file(input_file, series_data, period_dict, start_year):\n",
    "    try:\n",
    "        # Read the data file\n",
    "        data = pd.read_csv(input_file, sep='\\t', engine='python')\n",
    "\n",
    "        # Strip any whitespace characters from the column names\n",
    "        data.columns = data.columns.str.strip()\n",
    "\n",
    "        # Explicitly clean the series_id column for consistency\n",
    "        data['series_id'] = data['series_id'].astype(str).str.strip()\n",
    "\n",
    "        # Convert the year column to numeric for filtering and filter rows based on the start_year\n",
    "        data['year'] = pd.to_numeric(data['year'], errors='coerce')\n",
    "        data = data[data['year'] >= start_year]\n",
    "\n",
    "        # Map period code to name using period_dict\n",
    "        data['period'] = data['period'].map(period_dict)\n",
    "\n",
    "        # Merge with series data based on series_id\n",
    "        merged_data = pd.merge(data, series_data, on='series_id', how='left')\n",
    "\n",
    "        # Keep only the relevant columns\n",
    "        final_data = merged_data[['series_id', 'year', 'value', \n",
    "                                  'supersector', 'industry', 'datatype', 'period']]\n",
    "\n",
    "        # Filter out rows where datatype starts with \"INDEXES\"\n",
    "        final_data = final_data[~final_data['datatype'].str.startswith(\"INDEXES\", na=False)]\n",
    "\n",
    "        return final_data\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError encountered: {e}. Check column names or data.\")\n",
    "        raise\n",
    "\n",
    "# Main function to execute the process\n",
    "def main():\n",
    "    # Define the start year for filtering to decrease output file size; change as needed (first available year is 2006)\n",
    "    start_year = 2014  \n",
    "\n",
    "    # Define file paths\n",
    "    supersector_dict_path = 'dictionaries/ce.supersector.txt'\n",
    "    industry_dict_path = 'dictionaries/ce.industry.txt'\n",
    "    datatype_dict_path = 'dictionaries/ce.datatype.txt'\n",
    "    period_dict_path = 'dictionaries/ce.period.txt'\n",
    "    series_file = 'ce.series.txt'\n",
    "\n",
    "    # Define input files and corresponding output files\n",
    "    input_output_files = [\n",
    "        ('ce.data.02b.AllRealEarningsAE.txt', 'ce_AllEarnAE_processed_data.csv'),\n",
    "        ('ce.data.05b.TotalPrivate.AllEmployeeHoursAndEarnings.txt', 'ce_TotalPrivateAEHrsEarn_processed_data.csv'),\n",
    "        ('ce.data.50b.Information.AllEmployeeHoursAndEarnings.txt', 'ce_InfoAEHrsEarn_processed_data.csv'),\n",
    "        ('ce.data.55b.FinancialActivities.AllEmployeeHoursAndEarnings.txt', 'ce_FinlAEHrsEarn_processed_data.csv'),\n",
    "        ('ce.data.60b.ProfessionalBusinessServices.AllEmployeeHoursAndEarnings.txt', 'ce_ProfAEHrsEarn_processed_data.csv'),\n",
    "        ('ce.data.65b.EducationAndHealthCare.AllEmployeeHoursAndEarnings.txt', 'ce_EducHlthAEHrsEarn_processed_data.csv'),\n",
    "        ('ce.data.70b.LeisureAndHospitality.AllEmployeeHoursAndEarnings.txt', 'ce_LeisAEHrsEarn_processed_data.csv'),\n",
    "        ('ce.data.80b.OtherServices.AllEmployeeHoursAndEarnings.txt', 'ce_OtherAEHrsEarn_processed_data.csv')\n",
    "    ]\n",
    "\n",
    "    # Load dictionaries\n",
    "    print(\"Loading dictionaries...\")\n",
    "    try:\n",
    "        supersector_dict, industry_dict, datatype_dict, period_dict = load_dictionaries(supersector_dict_path, industry_dict_path, datatype_dict_path, period_dict_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dictionaries: {e}\")\n",
    "        return  # Exit if there is an error loading the dictionaries\n",
    "\n",
    "    # Process series file\n",
    "    print(\"Processing series file...\")\n",
    "    try:\n",
    "        series_data = process_series_file(series_file, supersector_dict, industry_dict, datatype_dict)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing series file: {e}\")\n",
    "        return  # Exit the function if error occurs in processing series file\n",
    "\n",
    "    # Process each data input file, save to csv output file, print to console # rows for each resulting data set\n",
    "    for input_file, output_file in input_output_files:\n",
    "        print(f\"Processing {input_file}...\")\n",
    "        try:\n",
    "            final_data = process_HrsEarn_file(input_file, series_data, period_dict, start_year)\n",
    "            final_data.to_csv(output_file, index=False)\n",
    "            print(f\"Saved processed data to {output_file}. Number of rows: {len(final_data)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {input_file}: {e}\")\n",
    "            return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b4da57-1be9-4f71-b4e8-e14eb53568b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
